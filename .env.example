# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_KEY=your_api_key_here

# API Version - you can use either variable name:
AZURE_OPENAI_API_VERSION=2025-03-01-preview

# Github CLI Configuration
GITHUB_TOKEN=your_github_token_here

# GitLab Configuration (Optional)
# Configure these to enable GitLab integration for issues, merge requests, and pipelines
# GITLAB_URL=https://community.opengroup.org
# GITLAB_TOKEN=your_gitlab_personal_access_token
# GITLAB_DEFAULT_GROUP=osdu

# OSDU Agent Configuration
OSDU_AGENT_ORGANIZATION=azure
OSDU_AGENT_REPOSITORIES=partition,legal,entitlements,schema,file,storage,indexer,indexer-queue,search,workflow

# Copilot Wrapper Configuration (for fork/status/test commands)
COPILOT_ORGANIZATION=azure
COPILOT_TEMPLATE_REPO=azure/osdu-spi
COPILOT_DEFAULT_BRANCH=main
COPILOT_LOG_DIRECTORY=logs

# Model Selection (Optional)
# Override the default AI model used by copilot commands
# Options: claude-sonnet-4.5 (default), claude-haiku-4.5, gpt-5
# OSDU_AGENT_COPILOT_MODEL=claude-sonnet-4.5

# Maven MCP Server Configuration (Optional)
# Override the default pinned version (default: mvn-mcp-server==2.2.1)
# MAVEN_MCP_VERSION=mvn-mcp-server==2.3.0
# MAVEN_MCP_VERSION=mvn-mcp-server  # Use latest (not recommended for production)

# Observability Configuration (Optional)
# Azure Application Insights / Azure AI Foundry Integration
# Uncomment and configure to enable OpenTelemetry tracing and metrics
# APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=00000000-0000-0000-0000-000000000000;IngestionEndpoint=https://...
# OTEL_EXPORTER_OTLP_ENDPOINT=https://your-otel-collector:4318

# OpenTelemetry Settings (Optional)
# OTEL_TRACES_EXPORTER=otlp
# OTEL_METRICS_EXPORTER=otlp
# OTEL_LOGS_EXPORTER=otlp
